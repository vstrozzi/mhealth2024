{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the template for the submission. You can develop your algorithm in a regular Python script and copy the code here for submission.\n",
    "\n",
    "# TEAM NAME ON KAGGLE\n",
    "# Group33\n",
    "\n",
    "# GROUP NUMBER\n",
    "# \"group_33\"\n",
    "\n",
    "# TEAM MEMBERS (E-MAIL, LEGI, KAGGLE USERNAME):\n",
    "# \"vstrozzi@ethz.ch\", \"19-924-596\", \"vstrozzi\" \n",
    "# \"hdurand@ethz.ch\", \"18-815-761\", \"hlneds\"\n",
    "# \"nimholz@ethz.ch\", \"19-929-637\", \"nadineimholz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.signal import stft\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error, multilabel_confusion_matrix\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "import xgboost as xgb \n",
    "from scipy.signal import find_peaks, stft, istft\n",
    "import xgboost as xgb \n",
    "from scipy.signal import butter, lfilter\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording, Trace, Activity, WatchLocation, Path\n",
    "\n",
    "pd.options.display.max_seq_items = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Walking Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_RATE = 200\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype='band')\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def plot_signal(signal, title, ylabel, sampling_rate=SAMPLING_RATE, peaks=[]):\n",
    "    x = np.linspace(0, len(signal) / sampling_rate, len(signal))\n",
    "    t = pd.to_datetime(x, unit='s')\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(t if len(peaks) == 0 else np.linspace(0, len(signal), len(signal)) , signal)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Time [min:sec]' if len(peaks) == 0 else \"Indexes\")\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%M:%S'))\n",
    "    \n",
    "    # Plot peaks if given\n",
    "    if len(peaks) != 0:\n",
    "        plt.plot(peaks, signal[peaks], \"x\", color=\"green\")\n",
    "    plt.show()\n",
    "\n",
    "def get_signal_mag(ax, ay, az):\n",
    "\n",
    "    return (ax**2 + ay**2 + az**2)**0.5\n",
    "\n",
    "# Get magnitude walk\n",
    "def get_signal_walk(path):\n",
    "    recording = Recording(path)\n",
    "\n",
    "    # Magnitude\n",
    "    magn = get_signal_mag(recording.data['ax'].values, recording.data['ay'].values,  recording.data['az'].values)\n",
    "    \n",
    "    \n",
    "    return magn, 0\n",
    "\n",
    "# Clean low frequencies, RFFT since signals contain only real values (+faster)\n",
    "def algo_walk(acc_phase, label = 0, wind_length= 7.6, mov_avg_wind_s= 0.85, std_thr= 0.15000000000000002, std_wind= 0.65, freq_max_hz= 3.0, prom = 1.65, sampling_rate = SAMPLING_RATE, show=True):\n",
    "    # Number samples\n",
    "    N = len(acc_phase)\n",
    "    \n",
    "    # Filter too high frequency out\n",
    "    acc_phase = butter_bandpass_filter(acc_phase, 1, 3, sampling_rate)\n",
    "    # Eval moving average over window\n",
    "    mov_avg_wind = int(mov_avg_wind_s*sampling_rate)\n",
    "    numbers_series = pd.Series(acc_phase)\n",
    "\n",
    "    windows = numbers_series.rolling(mov_avg_wind, center=True)\n",
    "    moving_averages = windows.mean()\n",
    "\n",
    "    # Set first null entries from the list to zero\n",
    "    moving_averages = moving_averages.fillna(0)\n",
    "    acc_filt = moving_averages.to_numpy()\n",
    "\n",
    "    # Plot filered signal\n",
    "    if show:\n",
    "        plot_signal(acc_phase[40*sampling_rate:45*sampling_rate], 'Magnitude Acc Original', 'Amplitude')\n",
    "        plot_signal(acc_filt[40*sampling_rate:45*sampling_rate], 'Magnitude Acc Cleaned', 'Amplitude')\n",
    "\n",
    "    # Get peaks every windows sec\n",
    "    pred = 0\n",
    "\n",
    "    # Walking or movement detection first\n",
    "    step = int(std_wind*sampling_rate)\n",
    "    moving = np.empty(N)\n",
    "    for i in range(step, N - step):\n",
    "        std_l = lambda val: np.std(val[int(i - step):int(i + step)]) > std_thr\n",
    "        moving[i + step]  = std_l(acc_phase)\n",
    "            \n",
    "    # Copy for first and last\n",
    "    moving[0:step] = moving[step:2*step]\n",
    "    moving[-step:]= moving[-2*step:-step]\n",
    "    if show:\n",
    "        plot_signal(moving, \"Accel Signal\", \"Moving\")\n",
    "        plot_signal(acc_phase, \"Accel Signal original\", \"Moving\")\n",
    "    \n",
    "    \n",
    "    wind_step = int(wind_length*sampling_rate)\n",
    "    for i in range(0, N, wind_step):\n",
    "        acc_wind_filt = acc_filt[i:(i+ wind_step)]\n",
    "        acc_wind_orig = acc_phase[i:(i+ wind_step)]\n",
    "        moving_wind = moving[i:(i+ wind_step)]\n",
    "\n",
    "        # Normalize\n",
    "        # Here you can modify freely the parameters of find peak\n",
    "        # Minimum distance for our peaks is len_signal_per_minute/max_acc_beat (30 seconds)\n",
    "        distance = 1/freq_max_hz*sampling_rate\n",
    "        prominence = (np.max(acc_wind_filt) - np.min(acc_wind_filt))/prom\n",
    "        peaks, _ = find_peaks(acc_wind_filt, height = np.mean(acc_wind_filt), distance=distance, prominence=prominence)\n",
    "        \n",
    "        # Keeps peaks only where energy is not too low\n",
    "        peaks = [peak for peak in peaks if moving_wind[peak]]\n",
    "        # Find peaks with double heel, remove half\n",
    "        pred += len(peaks)\n",
    "        \n",
    "\n",
    "        # Plot example in range\n",
    "        if i == 8*wind_step and show:\n",
    "            plot_signal(acc_wind_orig, 'Acc Orig from {} to {} s'.format(i*sampling_rate, (i+ 10)*sampling_rate), 'Amplitude', peaks=peaks)\n",
    "            plot_signal(acc_wind_filt, 'Acc Filt from {} to {} s'.format(i*sampling_rate, (i+ 10)*sampling_rate), 'Amplitude', peaks=peaks)\n",
    "            plot_signal(moving_wind, 'Acc wrist Filt from {} to {} s'.format(i*sampling_rate, (i+ 10)*sampling_rate), 'Amplitude', peaks=peaks)\n",
    "\n",
    "    # Print prediction of score if given heart rate ground truth\n",
    "    if label != 0:   \n",
    "        print(\"We have found {} compared to the gt of {} steps\".format(pred, label))\n",
    "    return pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR_DIFF_SAMPLE_RATE = [\"mx\", \"my\", \"mz\", \"altitude\"]\n",
    "MEASURES = [\"mean\", \"std\", \"energy\", \"max_freq\"]\n",
    "SENSOR_CORR = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\", \"mx\", \"my\", \"mz\", \"altitude\"]\n",
    "METRICS = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\", \"mx\", \"my\", \"mz\", \"altitude\", \"Steps\", \"StepsWindow\"]\n",
    "MAX_LENGTH = 919.935\n",
    "\n",
    "\n",
    "# Get features per sample across windows\n",
    "def features_per_sample(df):\n",
    "    mean = df.groupby('Sample').mean()\n",
    "    mean = mean.add_prefix(\"mean_\")\n",
    "    std = df.groupby('Sample').std()\n",
    "    std = std.add_prefix(\"std_\")\n",
    "\n",
    "    quantile25 = df.groupby('Sample').quantile(q=0.25)\n",
    "    quantile25 = quantile25.add_prefix(\"q25_\")\n",
    "\n",
    "    quantile75 = df.groupby('Sample').quantile(q=0.75)\n",
    "    quantile75 = quantile75.add_prefix(\"q75_\")\n",
    "\n",
    "    df_final =  pd.concat([mean, std, quantile25, quantile75], axis = 1)\n",
    "    return df_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only features. Attention, features_corr need to give feats in correct order ex. ax, az, gx, gy, mz\n",
    "def drop_features(df, features, features_corr, measures):\n",
    "    corr_feats = [x for x in df.columns for y in features_corr if y in x]\n",
    "    features_measures = [x for x in df.columns for y in features if y in x]\n",
    "    measures_drop = [x for x in df.columns for y in measures if y in x]\n",
    "    return df.drop(features_measures + corr_feats + measures_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend the df to have at least max_window elements per sample, where the padding is with 0\n",
    "def extend_df_windows(df, data_every = 30, wind_length_s = 60, wind_overlap_per = 0.5):\n",
    "    wind_step = wind_length_s*wind_overlap_per\n",
    "    max_window = int((MAX_LENGTH)//wind_step)\n",
    "\n",
    "    # Create max_window consecutive rows\n",
    "    df['g'] = df.groupby('Sample').cumcount()\n",
    "    mux = pd.MultiIndex.from_product([df['Sample'].unique(), range(max_window)], names=('Sample','g'))\n",
    "\n",
    "    df = (df.set_index(['Sample','g'])\n",
    "        .reindex(mux, fill_value=0)\n",
    "        .reset_index(level=1, drop=True)\n",
    "        .reset_index())\n",
    "    \n",
    "\n",
    "    # Reduce number of rows by\n",
    "    rol = max_window//data_every\n",
    "\n",
    "    df_label = df[[\"Sample\"]].iloc[rol - 1::rol, :]\n",
    "    df = df.drop([\"Sample\"], axis=1).rolling(rol).mean() \n",
    "\n",
    "    df = df.iloc[rol - 1::rol, :]\n",
    "    \n",
    "    df = pd.concat([df_label, df], axis = 1).reset_index(drop=True)\n",
    "                \n",
    "    # Group every max_window rows\n",
    "    s = df.groupby(['Sample']).cumcount()\n",
    "\n",
    "    df1 = df.set_index(['Sample', s]).unstack().sort_index(level=1, axis=1)\n",
    "    df1.columns = [f'{x}{y}' for x, y in df1.columns]\n",
    "    df1 = df1.reset_index()\n",
    "\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_drop = [\"energy\"]\n",
    "features_train_remove = [\"Frequency\", \"path_idx\", \"watch_loc\", \"Length\", \"Steps\", \"STANDING\", \"Timestamps\", \"WALKING\",\t\"RUNNING\",\t\"CYCLING\"]\n",
    "\n",
    "features_watch_remove = [\"altitude\", \"Steps\", \"StepsWindow\", \"mx\", \"my\", \"mz\"]\n",
    "features_activ_remove = [\"altitude\", \"mx\", \"my\", \"mz\"]\n",
    "\n",
    "features_path_remove = [\"ax\", \"ay\", \"az\", \"gx\", \"gy\", \"gz\"]\n",
    "measures_drop_path = [\"energy\", \"max_freq\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_watch = pickle.load(open(\"group33_model_watch.pkl\", \"rb\"))\n",
    "clf_path =  pickle.load(open(\"group33_model_path.pkl\", \"rb\"))\n",
    "clf_activ = pickle.load(open(\"group33_model_activ.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path for all test traces\n",
    "dir_traces = \"./data/test/\"#'/kaggle/input/24-exercise2/data/test'\n",
    "\n",
    "filenames = [join(dir_traces, f) for f in listdir(dir_traces) if isfile(join(dir_traces, f))]\n",
    "filenames.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Id': 1, 'watch_loc': 0, 'path_idx': 4, 'standing': False, 'walking': False, 'running': True, 'cycling': False, 'step_count': 336}\n",
      "We have elaborated 1 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Get number steps\u001b[39;00m\n\u001b[1;32m     53\u001b[0m sign, _ \u001b[38;5;241m=\u001b[39m get_signal_walk(filename)\n\u001b[0;32m---> 54\u001b[0m nr_steps \u001b[38;5;241m=\u001b[39m \u001b[43malgo_walk\u001b[49m\u001b[43m(\u001b[49m\u001b[43msign\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m exit()\n\u001b[1;32m     57\u001b[0m pred_activ_sample \u001b[38;5;241m=\u001b[39m pred_activ[idx]\n",
      "Cell \u001b[0;32mIn[60], line 72\u001b[0m, in \u001b[0;36malgo_walk\u001b[0;34m(acc_phase, label, wind_length, mov_avg_wind_s, std_thr, std_wind, freq_max_hz, prom, sampling_rate, show)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(step, N \u001b[38;5;241m-\u001b[39m step):\n\u001b[1;32m     71\u001b[0m     std_l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m val: np\u001b[38;5;241m.\u001b[39mstd(val[\u001b[38;5;28mint\u001b[39m(i \u001b[38;5;241m-\u001b[39m step):\u001b[38;5;28mint\u001b[39m(i \u001b[38;5;241m+\u001b[39m step)]) \u001b[38;5;241m>\u001b[39m std_thr\n\u001b[0;32m---> 72\u001b[0m     moving[i \u001b[38;5;241m+\u001b[39m step]  \u001b[38;5;241m=\u001b[39m \u001b[43mstd_l\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc_phase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Copy for first and last\u001b[39;00m\n\u001b[1;32m     75\u001b[0m moving[\u001b[38;5;241m0\u001b[39m:step] \u001b[38;5;241m=\u001b[39m moving[step:\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mstep]\n",
      "Cell \u001b[0;32mIn[60], line 71\u001b[0m, in \u001b[0;36malgo_walk.<locals>.<lambda>\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m     69\u001b[0m moving \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(N)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(step, N \u001b[38;5;241m-\u001b[39m step):\n\u001b[0;32m---> 71\u001b[0m     std_l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m val: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m std_thr\n\u001b[1;32m     72\u001b[0m     moving[i \u001b[38;5;241m+\u001b[39m step]  \u001b[38;5;241m=\u001b[39m std_l(acc_phase)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Copy for first and last\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3645\u001b[0m, in \u001b[0;36mstd\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m   3642\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3643\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m std(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, ddof\u001b[38;5;241m=\u001b[39mddof, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3646\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:206\u001b[0m, in \u001b[0;36m_std\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_std\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, ddof\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    205\u001b[0m          where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 206\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m               \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    210\u001b[0m         ret \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39msqrt(ret, out\u001b[38;5;241m=\u001b[39mret)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:187\u001b[0m, in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# Most general case; includes handling object arrays containing imaginary\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# numbers and complex types with non-native byteorder\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     x \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mmultiply(x, um\u001b[38;5;241m.\u001b[39mconjugate(x), out\u001b[38;5;241m=\u001b[39mx)\u001b[38;5;241m.\u001b[39mreal\n\u001b[0;32m--> 187\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Compute degrees of freedom and make sure it is not negative.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m rcount \u001b[38;5;241m=\u001b[39m um\u001b[38;5;241m.\u001b[39mmaximum(rcount \u001b[38;5;241m-\u001b[39m ddof, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Loop through all filenames to process recordings (uncomment next # to run the code and compute features on the fly (slow))\n",
    "submission = []\n",
    "LOW_COR_FEATURES = ['ax_gx_corr', 'ax_gy_corr', 'ax_gz_corr', 'ax_mx_corr', 'ax_my_corr', 'ax_mz_corr', 'ax_altitude_corr', 'ay_gx_corr', 'ay_gy_corr', 'ay_gz_corr', 'ay_mx_corr', 'ay_my_corr', 'ay_mz_corr', 'ay_altitude_corr', 'az_gy_corr', 'az_gz_corr', 'az_mx_corr', 'az_my_corr', 'az_mz_corr', 'az_altitude_corr', 'gx_mx_corr', 'gx_my_corr', 'gx_mz_corr', 'gx_altitude_corr', 'gy_mx_corr', 'gy_my_corr', 'gy_mz_corr', 'gy_altitude_corr', 'gz_mx_corr', 'gz_my_corr', 'gz_mz_corr', 'gz_altitude_corr']\n",
    "PRELOAD_FEATURES = \"group33_features_test.csv\"\n",
    "df_test = pd.read_csv(PRELOAD_FEATURES)\n",
    "\n",
    "# Remove not highly correlated features\n",
    "df_test = df_test.drop(LOW_COR_FEATURES, axis=1)\n",
    "\n",
    "# Compute df for activities\n",
    "steps = df_test.groupby('Sample').max()[[\"Steps\"]]\n",
    "df_filt = df_test.drop([\"Frequency\", \"Length\", \"Timestamps\", \"Steps\"], axis=1)\n",
    "\n",
    "df_filt = drop_features(df_filt, features_activ_remove, features_activ_remove, measures_drop)\n",
    "df_features_samples = features_per_sample(df_filt)\n",
    "X_active =  pd.concat([df_features_samples, steps[[\"Steps\"]]], axis=1)\n",
    "\n",
    "pred_activ = clf_activ.predict(X_active)\n",
    "\n",
    "# Compute df for path\n",
    "steps = df_test.groupby('Sample').max()[[\"Steps\"]]\n",
    "df_filt = df_test.drop([\"Frequency\", \"Length\", \"Timestamps\", \"Steps\"], axis=1)\n",
    "\n",
    "df_filt = drop_features(df_filt, features_path_remove, features_path_remove, measures_drop_path)\n",
    "# df_features_samples = features_per_sample(df_filt)\n",
    "df_features_samples = extend_df_windows(df_filt).set_index(\"Sample\")\n",
    "\n",
    "X_path =  pd.concat([df_features_samples, steps[[\"Steps\"]]], axis=1)\n",
    "\n",
    "pred_path = clf_path.predict(X_path)\n",
    "\n",
    "# Compute df for watch\n",
    "steps = df_test.groupby('Sample').max()[[\"Steps\"]]\n",
    "df_filt = df_test.drop([\"Frequency\", \"Length\", \"Timestamps\", \"Steps\"], axis=1)\n",
    "df_filt = drop_features(df_filt, features_watch_remove, features_watch_remove, measures_drop)\n",
    "\n",
    "df_features_samples = features_per_sample(df_filt)\n",
    "X_watch =  pd.concat([df_features_samples, steps[[\"Steps\"]]], axis=1)\n",
    "\n",
    "pred_watch = clf_watch.predict(X_watch)\n",
    "\n",
    "\n",
    "#data = pd.DataFrame()\n",
    "for idx, filename in enumerate(filenames):    \n",
    "    # Assumes filename format ends with a three-digit ID before \".pkl\"\n",
    "    match = re.search(r'(\\d{3})\\.pkl$', filename)\n",
    "    if match:\n",
    "        id = int(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f'Filename {filename} does not match expected format')    \n",
    "\n",
    "    # Get number steps\n",
    "    sign, _ = get_signal_walk(filename)\n",
    "    nr_steps = algo_walk(sign, show=False)\n",
    "    exit()\n",
    "\n",
    "    pred_activ_sample = pred_activ[idx]\n",
    "\n",
    "    # Get path\n",
    "    pred_path_sample = pred_path[idx]\n",
    "\n",
    "    # Get watch loc\n",
    "    pred_watch_sample = pred_watch[idx]\n",
    "    \n",
    "    # Placeholder for the algorithm to process the recording\n",
    "    # Implement the logic to infer watch location, path index, step count,\n",
    "    # and activities (standing, walking, running, cycling) here.\n",
    "    # Ensure your algorithm is tolerant to missing data and does not crash\n",
    "    # when optional smartphone data traces are missing.\n",
    "\n",
    "    path_idx = pred_path_sample  # Integer, path in {0, 1, 2, 3, 4}\n",
    "    watch_loc = pred_watch_sample  # Integer, 0: left wrist, 1: belt, 2: right ankle\n",
    "    standing = bool(pred_activ_sample[0])  # Boolean, True if participant was standing still throughout the recording\n",
    "    walking = bool(pred_activ_sample[1])  # Boolean, True if participant was walking throughout the recording\n",
    "    running = bool(pred_activ_sample[2])  # Boolean, True if participant was running throughout the recording\n",
    "    cycling = bool(pred_activ_sample[3])  # Boolean, True if participant was cycling throughout the recording\n",
    "    step_count = nr_steps  # Integer, number of steps, must be provided for each recording\n",
    "\n",
    "    predictions = {\n",
    "        'Id': id, \n",
    "        'watch_loc': watch_loc, \n",
    "        'path_idx': path_idx,\n",
    "        'standing': standing,\n",
    "        'walking': walking,\n",
    "        'running': running,\n",
    "        'cycling': cycling,\n",
    "        'step_count': step_count\n",
    "        }\n",
    "\n",
    "    submission.append(predictions)\n",
    "\n",
    "    if idx % 30 == 1:\n",
    "        print(predictions)\n",
    "        print(\"We have elaborated {} samples\".format(idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the predicted values into a .csv file to then upload the .csv file to Kaggle\n",
    "# When cross-checking the .csv file on your computer, we recommend using a text editor and NOT excel so that the results are displayed correctly\n",
    "# IMPORTANT: Do NOT change the name of the columns of the .csv file (\"Id\", \"watch_loc\", \"path_idx\", \"standing\", \"walking\", \"running\", \"cycling\", \"step_count\")\n",
    "submission_df = pd.DataFrame(submission, columns=['Id', 'watch_loc', 'path_idx', 'standing', 'walking', 'running', 'cycling', 'step_count'])\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
